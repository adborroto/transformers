{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "missing-reporter",
   "metadata": {},
   "source": [
    "# Question and Answering with Transformers\n",
    "\n",
    "Question and answering is one of the most diverse and fast-moving areas of development in the world of transformers. In this notebook we will summarize a few of the key topics that we will later cover.\n",
    "\n",
    "## Types of Model\n",
    "\n",
    "**Open-Domain vs Reading Comprehension** - in QA we will often find that models will recieve a question, and (sometimes) extract an answer from a *context*. In the cases where this context is provided to the model alongside the question, eg:\n",
    "\n",
    "```\n",
    "{\n",
    "    'question': 'What field of study has a variety of unusual contexts?',\n",
    "    'context': 'The term \"matter\" is used throughout physics in a bewildering variety of contexts: for example, one refers to \"condensed matter physics\", \"elementary matter\", \"partonic\" matter, \"dark\" matter, \"anti\"-matter, \"strange\" matter, and \"nuclear\" matter. In discussions of matter and antimatter, normal matter has been referred to by Alfv√©n as koinomatter (Gk. common matter). It is fair to say that in physics, there is no broad consensus as to a general definition of matter, and the term \"matter\" usually is used in conjunction with a specifying modifier.'\n",
    "}\n",
    "```\n",
    "\n",
    "We would call this type of problem **Reading Comprehension** (RC). On the other hand we may be asking questions without providing a context. eg:\n",
    "\n",
    "```\n",
    "{\n",
    "    'question': 'What field of study has a variety of unusual contexts?'\n",
    "}\n",
    "```\n",
    "\n",
    "This type of problem is **Open-Domain** (OD), because the model must find our answers from elsewhere. There are two approaches to this *'elsewhere'* that we can use, these are open-book, and closed-book. Which we define as:\n",
    "\n",
    "* **Open-book** is where the model has access to an external source of data, such as the internet (eg Wikipedia), or your own documents (eg company policy).\n",
    "\n",
    "* **Closed-book** is where the model is relying on answers/information that it has encoded into it's own parameters during training.\n",
    "\n",
    "Finally, within **ODQA** (open-domain question answering), we have three model types to be considered.\n",
    "\n",
    "* **Retriever**, this is the model/architecture that *retrieves* a set of contexts for our Q&A model to extract answers from. The retriever extracts information from an external source and so this is only used in *open-book* ODQA.\n",
    "\n",
    "* **Reader**, this Q&A model takes a question and context and selects a span of the context which it believes answers the question. By itself this produces a **RC**QA model, but if paired with a *retriever* we create an **OD**QA model.\n",
    "\n",
    "* **Generator** this Q&A model takes a question (and optionally a context), and *generates* an answer. Unlike the reader which extracts the answer from a context, the generator using language generation to create an answer from scratch.\n",
    "\n",
    "These three models, when applied to **ODQA** can appear in three different architectures:\n",
    "\n",
    "* **Retriever-Reader** (open-book ODQA)\n",
    "\n",
    "* **Retriever-Generator** (open-book ODQA)\n",
    "\n",
    "* **Generator** (closed-book ODQA)\n",
    "\n",
    "![Question-answering model architectures for ODQA](../../assets/images/qa_model_architectures.png)\n",
    "\n",
    "We will be beginning this section by first introducing the SQuAD Q&A dataset, and then moving into **reader** and **generator** models. Next, we explore the different types of **retrievers**. And finally, begin putting these together to create fully-fledged Q&A systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
