{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Reddit Data\n",
    "\n",
    "There are two options for extracting data from Reddit:\n",
    "\n",
    "* The `requests` library, which will allow us to interface directly with the Reddit API.\n",
    "\n",
    "* The PRAW library, which is a wrapper library that adds an extra layer of abstraction in accessing the Reddit API.\n",
    "\n",
    "Here we will cover the first option, using the `requests` library to interface directly with the API.\n",
    "\n",
    "The final extraction script will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Reddit:\n",
    "    def __init__(self, client_id, secret_token, username, password):\n",
    "        # first create authentication object\n",
    "        auth = requests.auth.HTTPBasicAuth(client_id, secret_token)\n",
    "        # build login dictionary\n",
    "        login = {'grant_type': 'password',\n",
    "                 'username': username,\n",
    "                 'password': password}\n",
    "        # setup header info (incl description of API)\n",
    "        headers = {'User-Agent': 'MyBot/0.0.1'}\n",
    "        # send request for OAuth token\n",
    "        res = requests.post(f'https://www.reddit.com/api/v1/access_token',\n",
    "                            auth=auth, data=login, headers=headers)\n",
    "        # pull auth bearer token from response\n",
    "        token = res.json()['access_token']\n",
    "        # add authorization to headers dictionary\n",
    "        headers['Authorization'] = f'bearer {token}'\n",
    "        # add headers dict to internal attributes\n",
    "        self.headers = headers\n",
    "        # and api\n",
    "        self.api = 'https://oauth.reddit.com'\n",
    "\n",
    "    def get_new(self, subreddit, iters):\n",
    "        # initialize dataframe to store data\n",
    "        df = pd.DataFrame()\n",
    "        # initialize parameters dictionary\n",
    "        params = {'limit': 100}\n",
    "        # iterate through several times to make sure we get all the data available\n",
    "        for i in range(iters):\n",
    "            # make request\n",
    "            res = requests.get(f'{self.api}/r/{subreddit}/new',\n",
    "                               headers=self.headers,\n",
    "                               params=params)\n",
    "            # check that we returned something (if not we reached end)\n",
    "            if len(res.json()['data']['children']) == 0:\n",
    "                print('No more found')\n",
    "                return df\n",
    "            # iterate through each thread recieved\n",
    "            for thread in res.json()['data']['children']:\n",
    "                # add info to dataframe\n",
    "                df = df.append({\n",
    "                    'id': thread['data']['name'],\n",
    "                    'created_utc': int(thread['data']['created_utc']),\n",
    "                    'subreddit': thread['data']['subreddit'],\n",
    "                    'title': thread['data']['title'],\n",
    "                    'selftext': thread['data']['selftext'],\n",
    "                    'upvote_ratio': thread['data']['upvote_ratio'],\n",
    "                    'ups': thread['data']['ups'],\n",
    "                    'downs': thread['data']['downs'],\n",
    "                    'score': thread['data']['score']\n",
    "                }, ignore_index=True)\n",
    "            # get earliest ID\n",
    "            earliest = df['id'].iloc[len(df)-1]\n",
    "            # add earliest ID to params\n",
    "            params['after'] = earliest\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = 'investing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = '<CLIENT_ID>'\n",
    "SECRET_TOKEN = '<SECRET_TOKEN>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = '<USER>'\n",
    "PWD = '<PASSWORD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = Reddit(CLIENT_ID, SECRET_TOKEN, USER, PWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more found\n"
     ]
    }
   ],
   "source": [
    "data = reddit.get_new(SUB, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'|': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f'./data/reddit_{SUB}.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "ari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
