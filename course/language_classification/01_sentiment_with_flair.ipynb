{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment with Flair\n",
    "\n",
    "Flair offers models that we can use out-of-the-box. One of those is the English sentiment model, which we will learn how to use here.\n",
    "\n",
    "First, we need to make sure Flair has been installed, we do this in our CLI with:\n",
    "\n",
    "```\n",
    "pip install flair\n",
    "```\n",
    "\n",
    "Flair uses PyTorch/TensorFlow in under the hood, so it's essential that you also have one of the two libraries (or both) installed. There are a few steps in applying sentiment analysis, these are:\n",
    "\n",
    "1. Initializing the model.\n",
    "\n",
    "2. Tokenizing input text.\n",
    "\n",
    "3. Processing with the model.\n",
    "\n",
    "4. *(Optional) Formatting the outputs.*\n",
    "\n",
    "We then load the English sentiment model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In Transformers v4.0.0, the default path to cache downloaded models changed from '~/.cache/torch/transformers' to '~/.cache/huggingface/transformers'. Since you don't seem to have overridden and '~/.cache/torch/transformers' is a directory that exists, we're moving it to '~/.cache/huggingface/transformers' to avoid redownloading models you have already in the cache. You should only see this message once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 14:14:05,362 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to C:\\Users\\James\\AppData\\Local\\Temp\\tmpzozem642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 265512723/265512723 [00:21<00:00, 12074561.31B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 14:14:27,528 copying C:\\Users\\James\\AppData\\Local\\Temp\\tmpzozem642 to cache at C:\\Users\\James\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 14:14:27,611 removing temp file C:\\Users\\James\\AppData\\Local\\Temp\\tmpzozem642\n",
      "2021-03-06 14:14:27,624 loading file C:\\Users\\James\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9606d61bae407a8a14a68fc00a3f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a37af7fdb84828bfc76a286b118bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=466062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "model = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time this `load` method is run for the `'en-sentiment'` model the model will be downloaded. After this, the model is initialized. The `en-sentiment` model is a distilBERT model fitted with a classification head that outputs two classes - negative and positive.\n",
    "\n",
    "Our next step is to tokenize input text. For this we use the Flair `Sentence` object, which we initialize by passing our text into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"I like you . I love you\"   [− Tokens: 7]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I like you. I love you\"  # we are expecting a confidently positive sentiment here\n",
    "\n",
    "sentence = flair.data.Sentence(text)\n",
    "\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we now have the Flair `Sentence` object, which contains our text, alongside a *tokenized* version of it (each word/punctuation character is an individual token):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like you . I love you'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.to_tokenized_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to process our tokenized inputs through out distilBERT classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` method doesn't output our prediction, instead the predictions are added to our `sentence`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"I like you . I love you\"   [− Tokens: 7  − Sentence-Labels: {'label': [POSITIVE (0.9933)]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we are predicting a `POSITIVE` sentiment with a probability of `0.9933`, which is **very** confident as expected. Let's repeat the process with something more negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"I hate it when I 'm not learning\"   [− Tokens: 8  − Sentence-Labels: {'label': [NEGATIVE (0.9991)]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I hate it when I'm not learning\"\n",
    "sentence = flair.data.Sentence(text)\n",
    "model.predict(sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we correctly predict a `NEGATIVE` sentiment. Finally, we will typically want to extract our predictions and format them into the format that we need for our own use-case (for example plotting sentiment over time). Let's take a look at how we do that.\n",
    "\n",
    "The `Sentence` object provides us with a method called `get_labels`, we can use this to extract our sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NEGATIVE (0.9991)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this method we actually get a list, which contains our label object. To access each item in the list we need to dig a little deeper. We first access the label object by accessing the *0th* index of our list. Flair `Label` objects contain two attributes, `score` and `value` - which contain our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NEGATIVE (0.9991)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991464614868164"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()[0].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can access the label values directly (although not recommended) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9991464614868164, 'NEGATIVE')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.labels[0].score, sentence.labels[0].value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
