{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "ml",
   "display_name": "ML",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "First we will initialize our filiBERTo tokenizer like before, but within a `Dataset` object so that we will be ready to begin training our new model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # initialize the tokenizer using the tokenizer we initialized and saved to file\n",
    "        self.tokenizer = ByteLevelBPETokenizer(\n",
    "            './filiberto/filiberto-vocab.json',\n",
    "            './filiberto/filiberto-merges.txt'\n",
    "        )\n",
    "        # set [CLS] and [SEP] to be added to start-end of sequences\n",
    "        self.tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "            ('[SEP]', self.tokenizer.token_to_id('[SEP]')),\n",
    "            ('[CLS]', self.tokenizer.token_to_id('[CLS]'))\n",
    "        )\n",
    "        # truncate anything more than 512 tokens in length\n",
    "        self.tokenizer.enable_truncation(max_length=512)\n",
    "        # and enable padding to 512 too\n",
    "        self.tokenizer.enable_padding(length=512, pad_token='[PAD]')\n",
    "\n",
    "        paths = [str(x) for x in Path('../../data/text/oscar_it').glob('**/*.txt')]\n",
    "        # reorder paths (above will give text_999.txt as final file)\n",
    "        self.paths = [f'../../data/text/oscar_it/text_{i}.txt' for i in range(len(paths))]\n",
    "        # open the first file to get 'expected' length\n",
    "        with open(self.paths[0], 'r', encoding='utf-8') as fp:\n",
    "            lines = fp.read().split('\\n')\n",
    "        # save file length as 'expected' length\n",
    "        self.file_size = len(lines)\n",
    "\n",
    "    def __len__(self):\n",
    "        # we calculate the total number of examples as the number of samples in the\n",
    "        # first file, multipled by the number of files, minus the final value\n",
    "        length = self.file_size * len(self.paths) - self.file_size\n",
    "        with open(self.paths[-1], 'r', encoding='utf-8') as fp:\n",
    "            lines = fp.read().split('\\n')\n",
    "        length += len(lines)\n",
    "        return length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # get the file number and sample number based on i\n",
    "        file_i, sample_i = self.get_loc(i)\n",
    "        # load file\n",
    "        with open(self.paths[file_i], 'r', encoding='utf-8') as fp:\n",
    "            lines = fp.read().split('\\n')\n",
    "        # extract required sample\n",
    "        sample = lines[sample_i]\n",
    "        # encode\n",
    "        sample = self.tokenizer.encode(sample)\n",
    "        # convert tokens to tensor\n",
    "        try:\n",
    "            targets = torch.tensor(sample.ids)\n",
    "        except RuntimeError:\n",
    "            raise RuntimeError(f\"{sample=}\")\n",
    "        # create attention mask tensor\n",
    "        mask = torch.tensor(sample.attention_mask)\n",
    "        # mask ~15% of tokens to create inputs\n",
    "        input_ids = self.mlm(targets.detach().clone())\n",
    "        # return dictionary of input_ids, attention_mask, and labels\n",
    "        return {'input_ids': input_ids, 'attention_mask': mask, 'labels': targets}\n",
    "\n",
    "    def get_loc(self, i):\n",
    "        # get file number\n",
    "        file_num = int(i / self.file_size)\n",
    "        sample_num = i % self.file_size\n",
    "        return file_num, sample_num\n",
    "\n",
    "    def mlm(self, tensor):\n",
    "        # create random array of floats with equal dims to tensor\n",
    "        rand = torch.rand(tensor.shape)\n",
    "        # mask random 15% where token is not 0 [PAD], 1 [CLS], or 2 [SEP]\n",
    "        mask_arr = (rand < .15) * (tensor != 0) * (tensor != 1) * (tensor != 2)\n",
    "        # get indices of mask positions from mask array\n",
    "        mask_idx = torch.flatten(mask_arr.nonzero()).tolist()\n",
    "        # mask tensor and return\n",
    "        tensor[mask_idx] = 3\n",
    "        return tensor"
   ]
  },
  {
   "source": [
    "Next we initialize our `Dataset`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "source": [
    "And initialize the dataloader, which will load the data into the model during training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "source": [
    "And move onto building our model, we first need to create a BERT config object, which will describe which features we want to initialize our BERT model with."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=30_522,  # we align this to the tokenizer vocab set in previous notebook\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    pad_token_id=0\n",
    ")"
   ]
  },
  {
   "source": [
    "Then we import and initialize a BERT model with a language modeling head."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertLMHeadModel\n",
    "\n",
    "model = BertLMHeadModel(config)"
   ]
  },
  {
   "source": [
    "And now we move onto training. First we setup GPU/CPU usage."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "source": [
    "Now we move onto the training loop."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 0:   0%|          | 12/1782631 [00:37<1561:27:53,  3.15s/it, loss=6.26]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-2026db3ef752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# calculate loss for every parameter that needs grad update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m# update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "source": [
    "https://huggingface.co/blog/how-to-train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1782631"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-57060aa44edd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10_000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dataset.examples[10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1,\n",
       " 5401,\n",
       " 3580,\n",
       " 9800,\n",
       " 500,\n",
       " 2163,\n",
       " 16,\n",
       " 20411,\n",
       " 18,\n",
       " 2174,\n",
       " 300,\n",
       " 403,\n",
       " 330,\n",
       " 7787,\n",
       " 280,\n",
       " 582,\n",
       " 3756,\n",
       " 534,\n",
       " 8423,\n",
       " 1091,\n",
       " 904,\n",
       " 9178,\n",
       " 16,\n",
       " 1035,\n",
       " 7085,\n",
       " 275,\n",
       " 44820,\n",
       " 532,\n",
       " 311,\n",
       " 48933,\n",
       " 280,\n",
       " 480,\n",
       " 4144,\n",
       " 1419,\n",
       " 306,\n",
       " 1056,\n",
       " 267,\n",
       " 4667,\n",
       " 295,\n",
       " 477,\n",
       " 36444,\n",
       " 30,\n",
       " 478,\n",
       " 22318,\n",
       " 4028,\n",
       " 585,\n",
       " 26067,\n",
       " 292,\n",
       " 1139,\n",
       " 17694,\n",
       " 5220,\n",
       " 5007,\n",
       " 11765,\n",
       " 275,\n",
       " 11085,\n",
       " 441,\n",
       " 1117,\n",
       " 75,\n",
       " 16,\n",
       " 336,\n",
       " 662,\n",
       " 287,\n",
       " 40167,\n",
       " 280,\n",
       " 336,\n",
       " 776,\n",
       " 807,\n",
       " 42220,\n",
       " 13407,\n",
       " 376,\n",
       " 1309,\n",
       " 18,\n",
       " 18466,\n",
       " 2490,\n",
       " 23791,\n",
       " 338,\n",
       " 330,\n",
       " 6709,\n",
       " 275,\n",
       " 567,\n",
       " 1630,\n",
       " 35,\n",
       " 1041,\n",
       " 4330,\n",
       " 18,\n",
       " 458,\n",
       " 591,\n",
       " 926,\n",
       " 3136,\n",
       " 77,\n",
       " 35,\n",
       " 15908,\n",
       " 380,\n",
       " 3571,\n",
       " 4960,\n",
       " 2807,\n",
       " 1279,\n",
       " 856,\n",
       " 16,\n",
       " 1046,\n",
       " 478,\n",
       " 31378,\n",
       " 12137,\n",
       " 271,\n",
       " 27541,\n",
       " 528,\n",
       " 27337,\n",
       " 267,\n",
       " 10041,\n",
       " 275,\n",
       " 2947,\n",
       " 316,\n",
       " 352,\n",
       " 2785,\n",
       " 901,\n",
       " 305,\n",
       " 1647,\n",
       " 280,\n",
       " 316,\n",
       " 470,\n",
       " 7510,\n",
       " 379,\n",
       " 878,\n",
       " 7900,\n",
       " 16,\n",
       " 280,\n",
       " 3903,\n",
       " 891,\n",
       " 379,\n",
       " 1091,\n",
       " 303,\n",
       " 875,\n",
       " 316,\n",
       " 12215,\n",
       " 397,\n",
       " 18,\n",
       " 8936,\n",
       " 459,\n",
       " 287,\n",
       " 1535,\n",
       " 4733,\n",
       " 316,\n",
       " 1526,\n",
       " 4787,\n",
       " 682,\n",
       " 3247,\n",
       " 682,\n",
       " 853,\n",
       " 338,\n",
       " 330,\n",
       " 6639,\n",
       " 292,\n",
       " 1630,\n",
       " 18,\n",
       " 1232,\n",
       " 9434,\n",
       " 16,\n",
       " 280,\n",
       " 329,\n",
       " 10732,\n",
       " 1058,\n",
       " 805,\n",
       " 1088,\n",
       " 510,\n",
       " 391,\n",
       " 324,\n",
       " 380,\n",
       " 24952,\n",
       " 13,\n",
       " 2057,\n",
       " 49546,\n",
       " 509,\n",
       " 300,\n",
       " 29972,\n",
       " 9165,\n",
       " 275,\n",
       " 14681,\n",
       " 18,\n",
       " 13921,\n",
       " 16548,\n",
       " 36329,\n",
       " 41413,\n",
       " 515,\n",
       " 343,\n",
       " 17464,\n",
       " 16,\n",
       " 1382,\n",
       " 2578,\n",
       " 18,\n",
       " 3487,\n",
       " 750,\n",
       " 47260,\n",
       " 306,\n",
       " 1754,\n",
       " 7477,\n",
       " 16,\n",
       " 16224,\n",
       " 379,\n",
       " 18241,\n",
       " 1402,\n",
       " 343,\n",
       " 12749,\n",
       " 21220,\n",
       " 16,\n",
       " 372,\n",
       " 478,\n",
       " 1062,\n",
       " 1124,\n",
       " 1053,\n",
       " 454,\n",
       " 306,\n",
       " 5291,\n",
       " 1981,\n",
       " 18,\n",
       " 4009,\n",
       " 1149,\n",
       " 3364,\n",
       " 16,\n",
       " 1419,\n",
       " 36146,\n",
       " 18,\n",
       " 1202,\n",
       " 11518,\n",
       " 556,\n",
       " 343,\n",
       " 749,\n",
       " 2754,\n",
       " 16,\n",
       " 875,\n",
       " 343,\n",
       " 456,\n",
       " 3068,\n",
       " 30,\n",
       " 790,\n",
       " 3903,\n",
       " 317,\n",
       " 789,\n",
       " 280,\n",
       " 8744,\n",
       " 317,\n",
       " 469,\n",
       " 3963,\n",
       " 1136,\n",
       " 18,\n",
       " 13921,\n",
       " 343,\n",
       " 835,\n",
       " 7835,\n",
       " 35,\n",
       " 713,\n",
       " 4105,\n",
       " 16,\n",
       " 317,\n",
       " 1294,\n",
       " 15867,\n",
       " 848,\n",
       " 917,\n",
       " 316,\n",
       " 6940,\n",
       " 6557,\n",
       " 4116,\n",
       " 2249,\n",
       " 7007,\n",
       " 18,\n",
       " 11654,\n",
       " 528,\n",
       " 2249,\n",
       " 32147,\n",
       " 280,\n",
       " 317,\n",
       " 10558,\n",
       " 488,\n",
       " 459,\n",
       " 35,\n",
       " 4312,\n",
       " 330,\n",
       " 8142,\n",
       " 328,\n",
       " 27897,\n",
       " 835,\n",
       " 1653,\n",
       " 16,\n",
       " 844,\n",
       " 330,\n",
       " 3976,\n",
       " 376,\n",
       " 1538,\n",
       " 1631,\n",
       " 3444,\n",
       " 35,\n",
       " 4009,\n",
       " 317,\n",
       " 1630,\n",
       " 343,\n",
       " 379,\n",
       " 18241,\n",
       " 16,\n",
       " 1516,\n",
       " 16,\n",
       " 28431,\n",
       " 16,\n",
       " 528,\n",
       " 2249,\n",
       " 351,\n",
       " 3837,\n",
       " 18,\n",
       " 37,\n",
       " 26871,\n",
       " 16,\n",
       " 10047,\n",
       " 314,\n",
       " 275,\n",
       " 4435,\n",
       " 3261,\n",
       " 656,\n",
       " 13259,\n",
       " 16,\n",
       " 351,\n",
       " 7927,\n",
       " 16,\n",
       " 351,\n",
       " 24019,\n",
       " 16,\n",
       " 351,\n",
       " 3498,\n",
       " 1083,\n",
       " 270,\n",
       " 16,\n",
       " 351,\n",
       " 1048,\n",
       " 346,\n",
       " 1031,\n",
       " 16,\n",
       " 1062,\n",
       " 7443,\n",
       " 280,\n",
       " 837,\n",
       " 582,\n",
       " 27496,\n",
       " 18,\n",
       " 38440,\n",
       " 380,\n",
       " 2150,\n",
       " 3272,\n",
       " 317,\n",
       " 789,\n",
       " 290,\n",
       " 1934,\n",
       " 672,\n",
       " 303,\n",
       " 1981,\n",
       " 17694,\n",
       " 5220,\n",
       " 5007,\n",
       " 11765,\n",
       " 387,\n",
       " 16,\n",
       " 368,\n",
       " 1905,\n",
       " 6465,\n",
       " 311,\n",
       " 3755,\n",
       " 267,\n",
       " 1945,\n",
       " 267,\n",
       " 8405,\n",
       " 272,\n",
       " 2323,\n",
       " 560,\n",
       " 18241,\n",
       " 18,\n",
       " 23797,\n",
       " 9932,\n",
       " 1914,\n",
       " 2049,\n",
       " 1197,\n",
       " 391,\n",
       " 21,\n",
       " 13,\n",
       " 1910,\n",
       " 1347,\n",
       " 391,\n",
       " 21,\n",
       " 13,\n",
       " 1975,\n",
       " 1347,\n",
       " 391,\n",
       " 22,\n",
       " 13,\n",
       " 2049,\n",
       " 1347,\n",
       " 391,\n",
       " 23,\n",
       " 13,\n",
       " 1971,\n",
       " 1347,\n",
       " 391,\n",
       " 25,\n",
       " 13,\n",
       " 1910,\n",
       " 1369,\n",
       " 391,\n",
       " 24,\n",
       " 13,\n",
       " 1766,\n",
       " 1369,\n",
       " 391,\n",
       " 22,\n",
       " 13,\n",
       " 1810,\n",
       " 1369,\n",
       " 391,\n",
       " 23,\n",
       " 13,\n",
       " 1945,\n",
       " 1369,\n",
       " 391,\n",
       " 22,\n",
       " 13,\n",
       " 1794,\n",
       " 1369,\n",
       " 391,\n",
       " 23,\n",
       " 13,\n",
       " 2051,\n",
       " 1369,\n",
       " 391,\n",
       " 23,\n",
       " 13,\n",
       " 1975,\n",
       " 1369,\n",
       " 391,\n",
       " 24,\n",
       " 13,\n",
       " 2049,\n",
       " 1369,\n",
       " 391,\n",
       " 27,\n",
       " 13,\n",
       " 1971,\n",
       " 1369,\n",
       " 391,\n",
       " 22,\n",
       " 13,\n",
       " 1910,\n",
       " 1522,\n",
       " 391,\n",
       " 1885,\n",
       " 13,\n",
       " 1766,\n",
       " 1522,\n",
       " 391,\n",
       " 23,\n",
       " 13,\n",
       " 1730,\n",
       " 1522,\n",
       " 391,\n",
       " 25,\n",
       " 13,\n",
       " 1810,\n",
       " 1522,\n",
       " 391,\n",
       " 26,\n",
       " 13,\n",
       " 1945,\n",
       " 1522,\n",
       " 391,\n",
       " 21,\n",
       " 13,\n",
       " 1794,\n",
       " 1522,\n",
       " 391,\n",
       " 22,\n",
       " 13,\n",
       " 1015,\n",
       " 1522,\n",
       " 391,\n",
       " 23,\n",
       " 13,\n",
       " 2051,\n",
       " 1522,\n",
       " 391,\n",
       " 22,\n",
       " 13,\n",
       " 1910,\n",
       " 1660,\n",
       " 391,\n",
       " 27,\n",
       " 13,\n",
       " 1766,\n",
       " 1660,\n",
       " 391,\n",
       " 21,\n",
       " 13,\n",
       " 1730,\n",
       " 1660,\n",
       " 391,\n",
       " 22,\n",
       " 13,\n",
       " 1810,\n",
       " 1660,\n",
       " 391,\n",
       " 21,\n",
       " 13,\n",
       " 2183,\n",
       " 1660,\n",
       " 391,\n",
       " 21,\n",
       " 13,\n",
       " 1945,\n",
       " 1660,\n",
       " 2]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "dataset.examples[9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}